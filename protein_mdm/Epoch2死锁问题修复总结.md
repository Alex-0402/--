# Epoch 2 æ­»é”é—®é¢˜ä¿®å¤æ€»ç»“

## ğŸ” é—®é¢˜åˆ†æ

### ç°è±¡
ä»é”™è¯¯æ—¥å¿—å¯ä»¥çœ‹åˆ°ï¼š
1. **Epoch 1 æˆåŠŸå®Œæˆ**ï¼šæ‰€æœ‰è¿›ç¨‹éƒ½å¤„ç†äº† 61 ä¸ªæ‰¹æ¬¡ï¼ŒåŒæ­¥æˆåŠŸ
2. **Epoch 2 å¼€å§‹æ—¶æ­»é”**ï¼š
   - Rank 1-7 å·²ç»é€šè¿‡äº†"å¼€å§‹è¿­ä»£å‰çš„ barrier"å¹¶å¼€å§‹è¿­ä»£æ•°æ®
   - Rank 0 è¿˜åœ¨ç­‰å¾…"å¼€å§‹è¿­ä»£å‰çš„ barrier"
   - 30åˆ†é’Ÿåï¼ˆ1800ç§’ï¼‰NCCL è¶…æ—¶ï¼š`WorkNCCL(SeqNum=397, OpType=ALLREDUCE, ...) ran for 1800081 milliseconds before timing out`

### æ ¹æœ¬åŸå› 

**ä¸»è¦é—®é¢˜**ï¼š`persistent_workers=True` åœ¨ epoch åˆ‡æ¢æ—¶å¯¼è‡´ worker è¿›ç¨‹çŠ¶æ€ä¸ä¸€è‡´

1. **persistent_workers=True çš„é—®é¢˜**ï¼š
   - å½“ `persistent_workers=True` æ—¶ï¼ŒDataLoader çš„ worker è¿›ç¨‹åœ¨ epoch ä¹‹é—´ä¿æŒæ´»è·ƒ
   - åœ¨ epoch åˆ‡æ¢æ—¶ï¼Œè¿™äº› worker è¿›ç¨‹å¯èƒ½å¤„äºä¸ä¸€è‡´çš„çŠ¶æ€
   - Rank 0 åœ¨åˆ›å»ºè¿­ä»£å™¨æ—¶ï¼Œå¯èƒ½è¢« worker è¿›ç¨‹é˜»å¡ï¼Œå¯¼è‡´æ— æ³•åŠæ—¶åˆ°è¾¾ barrier
   - å…¶ä»–è¿›ç¨‹ï¼ˆRank 1-7ï¼‰å·²ç»é€šè¿‡äº† barrier å¹¶å¼€å§‹è¿­ä»£ï¼Œä½† Rank 0 è¿˜åœ¨ç­‰å¾… barrier

2. **Barrier åŒæ­¥é—®é¢˜**ï¼š
   - Rank 0 åœ¨åˆ›å»ºè¿­ä»£å™¨æ—¶è¢«é˜»å¡ï¼Œæ— æ³•åˆ°è¾¾ barrier
   - å…¶ä»–è¿›ç¨‹å·²ç»é€šè¿‡äº† barrier å¹¶å¼€å§‹è¿­ä»£
   - è¿™å¯¼è‡´ Rank 0 æ°¸è¿œæ— æ³•åˆ°è¾¾ barrierï¼Œé€ æˆæ­»é”

## âœ… ä¿®å¤æ–¹æ¡ˆ

### 1. å°† persistent_workers æ”¹å› False

**ä¿®æ”¹ä½ç½®**ï¼š`train.py`

```python
# ä¿®å¤å‰
persistent_workers=True,  # âŒ åœ¨ epoch åˆ‡æ¢æ—¶å¯èƒ½å¯¼è‡´æ­»é”

# ä¿®å¤å
persistent_workers=False,  # âœ… ä¿®å¤ï¼špersistent_workers=True åœ¨ epoch åˆ‡æ¢æ—¶å¯èƒ½å¯¼è‡´æ­»é”
```

**åŸå› **ï¼š
- `persistent_workers=False` æ—¶ï¼Œæ¯ä¸ª epoch éƒ½ä¼šé‡æ–°å¯åŠ¨ worker è¿›ç¨‹
- è¿™ç¡®ä¿ worker è¿›ç¨‹åœ¨ epoch åˆ‡æ¢æ—¶å®Œå…¨é‡ç½®ï¼Œé¿å…çŠ¶æ€ä¸ä¸€è‡´
- è™½ç„¶ä¼šæœ‰ä¸€äº›æ€§èƒ½å¼€é”€ï¼ˆé‡æ–°å¯åŠ¨è¿›ç¨‹ï¼‰ï¼Œä½†é¿å…äº†æ­»é”é—®é¢˜

### 2. åœ¨ epoch åˆ‡æ¢æ—¶æ·»åŠ åŒæ­¥ç‚¹

**ä¿®æ”¹ä½ç½®**ï¼š`training/trainer.py`

åœ¨ epoch å¾ªç¯å¼€å§‹æ—¶ï¼Œæ·»åŠ ä¸€ä¸ª barrier ç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½å®Œå…¨åŒæ­¥ï¼š

```python
for epoch in range(start_epoch, num_epochs + 1):
    # âœ… ä¿®å¤ï¼šåœ¨ epoch åˆ‡æ¢æ—¶ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½å®Œå…¨åŒæ­¥
    # è¿™ç¡®ä¿ DataLoader çš„ worker è¿›ç¨‹ï¼ˆå¦‚æœ persistent_workers=Falseï¼‰å®Œå…¨å…³é—­
    if self.ddp_enabled:
        import torch.distributed as dist
        import sys
        sys.stdout.flush()
        if self.rank == 0:
            print(f"[Rank 0] Epoch {epoch} å¼€å§‹å‰ï¼ŒåŒæ­¥æ‰€æœ‰è¿›ç¨‹...", flush=True)
        dist.barrier()
        if self.rank == 0:
            print(f"[Rank 0] Epoch {epoch} å¼€å§‹å‰ï¼Œæ‰€æœ‰è¿›ç¨‹å·²åŒæ­¥", flush=True)
    
    # æ¸…ç†å†…å­˜å’Œæ˜¾å­˜
    import gc
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    self.current_epoch = epoch
    # ... ç»§ç»­è®­ç»ƒ
```

### 3. ä¼˜åŒ–è¿­ä»£å™¨åˆ›å»ºé€»è¾‘

**ä¿®æ”¹ä½ç½®**ï¼š`training/trainer.py`

åœ¨åˆ›å»ºè¿­ä»£å™¨å‰ï¼Œç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½åˆ·æ–°ï¼Œå¹¶æ·»åŠ æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼š

```python
# âœ… ä¿®å¤ï¼šåœ¨åˆ›å»ºè¿­ä»£å™¨å‰ï¼Œç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½åˆ·æ–°
import sys
sys.stdout.flush()
print(f"[Rank {self.rank}] æ­£åœ¨åˆ›å»ºè¿­ä»£å™¨...", flush=True)
data_iter = iter(self.train_loader)
print(f"[Rank {self.rank}] è¿­ä»£å™¨åˆ›å»ºæˆåŠŸ", flush=True)
```

## ğŸ“‹ ä¿®æ”¹çš„æ–‡ä»¶

1. **`train.py`**ï¼š
   - å°†æ‰€æœ‰ DataLoader çš„ `persistent_workers` ä» `True` æ”¹ä¸º `False`
   - åŒ…æ‹¬è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ DataLoaderï¼ˆDDP å’Œå• GPU æ¨¡å¼ï¼‰

2. **`training/trainer.py`**ï¼š
   - åœ¨ epoch å¾ªç¯å¼€å§‹æ—¶æ·»åŠ åŒæ­¥ barrier
   - ä¼˜åŒ–è¿­ä»£å™¨åˆ›å»ºé€»è¾‘ï¼Œç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½åˆ·æ–°

## ğŸ§ª æµ‹è¯•å»ºè®®

1. **é‡æ–°å¯åŠ¨è®­ç»ƒ**ï¼Œè§‚å¯Ÿæ˜¯å¦è¿˜æœ‰æ­»é”
2. **æ£€æŸ¥æ—¥å¿—**ï¼Œç¡®è®¤æ‰€æœ‰è¿›ç¨‹éƒ½é€šè¿‡äº†å„ä¸ª barrier
3. **å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨**ï¼Œå¯ä»¥è€ƒè™‘ï¼š
   - å°† `num_workers` ä» 4 æ”¹ä¸º 2 æˆ– 0
   - æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–é˜»å¡æ“ä½œ

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ€§èƒ½è€ƒè™‘**ï¼š
   - `persistent_workers=False` ä¼šå¯¼è‡´æ¯ä¸ª epoch éƒ½é‡æ–°å¯åŠ¨ worker è¿›ç¨‹
   - è¿™ä¼šæœ‰ä¸€äº›æ€§èƒ½å¼€é”€ï¼Œä½†é¿å…äº†æ­»é”é—®é¢˜
   - å¦‚æœæ•°æ®åŠ è½½ä¸æ˜¯ç“¶é¢ˆï¼Œè¿™ä¸ªå¼€é”€æ˜¯å¯ä»¥æ¥å—çš„

2. **å†…å­˜æ¸…ç†**ï¼š
   - åœ¨ epoch åˆ‡æ¢æ—¶æ¸…ç†å†…å­˜å’Œæ˜¾å­˜ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
   - ä½¿ç”¨ `gc.collect()` å’Œ `torch.cuda.empty_cache()`

3. **åŒæ­¥ç‚¹**ï¼š
   - åœ¨ epoch åˆ‡æ¢æ—¶æ·»åŠ åŒæ­¥ç‚¹ï¼Œç¡®ä¿æ‰€æœ‰è¿›ç¨‹éƒ½å®Œå…¨åŒæ­¥
   - è¿™ç¡®ä¿ DataLoader çš„ worker è¿›ç¨‹å®Œå…¨å…³é—­åå†å¼€å§‹æ–°çš„ epoch

## ğŸ“ æ€»ç»“

âœ… **å·²å®Œæˆçš„ä¿®å¤**ï¼š
1. å°† `persistent_workers` ä» `True` æ”¹ä¸º `False`
2. åœ¨ epoch åˆ‡æ¢æ—¶æ·»åŠ åŒæ­¥ barrier
3. ä¼˜åŒ–è¿­ä»£å™¨åˆ›å»ºé€»è¾‘ï¼Œç¡®ä¿æ‰€æœ‰è¾“å‡ºéƒ½åˆ·æ–°
4. åœ¨ epoch åˆ‡æ¢æ—¶æ¸…ç†å†…å­˜å’Œæ˜¾å­˜

ç°åœ¨åº”è¯¥å¯ä»¥å®‰å…¨åœ°è¿›è¡Œå¤š epoch è®­ç»ƒï¼Œä¸ä¼šåœ¨ Epoch 2 å¼€å§‹æ—¶æ­»é”ã€‚
